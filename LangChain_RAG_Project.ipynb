{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5RjYraG2V+28PUVU8Eitd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/musman7888/Generative-AI-Projects---Batch-58/blob/main/LangChain_RAG_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tQZsMgcJCne"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet --upgrade langchain-text-splitters langchain-community langchain-google-genai  langchain-pinecone"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU pypdf"
      ],
      "metadata": {
        "id": "xxS4eYa7J1QY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "CmJ-EQh9KKF2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
      ],
      "metadata": {
        "id": "7pexThewKoZ1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
      ],
      "metadata": {
        "id": "5hmyPtbEK2Pc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "from pinecone import Pinecone,ServerlessSpec\n",
        "\n",
        "index_name = \"quickstart9\"\n",
        "pc = Pinecone(api_key=userdata.get('PINECONE_API_KEY'))\n",
        "\n",
        "pc.create_index(\n",
        "      name=index_name,\n",
        "      dimension=768, # Replace with your model dimensions\n",
        "      metric=\"cosine\", # Replace with your model metric\n",
        "      spec=ServerlessSpec(\n",
        "          cloud=\"aws\",\n",
        "          region=\"us-east-1\"\n",
        "      )\n",
        "  )\n",
        "\n",
        "index = pc.Index(index_name)\n",
        "\n",
        "vector_store = PineconeVectorStore(embedding=embeddings, index=index)"
      ],
      "metadata": {
        "id": "R0fqjJIFK8qR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "2sOE2d1YWsAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Load documents\n",
        "loader = TextLoader(\"documents.txt\")  # Replace with your file\n",
        "documents = loader.load()\n",
        "\n",
        "# Split documents into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=5)\n",
        "docs = text_splitter.split_documents(documents)\n",
        "print(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TAE0uQmJV37x",
        "outputId": "1aec0276-c7a6-4fbe-a371-a4bd9b4b12c4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(metadata={'source': 'documents.txt'}, page_content='Usman, born on 10th December, 1995 in Mandi'), Document(metadata={'source': 'documents.txt'}, page_content='Bahauddin, Pakistan. Did bachelors from'), Document(metadata={'source': 'documents.txt'}, page_content='from University of Sargodha. Now doing job in'), Document(metadata={'source': 'documents.txt'}, page_content='in Islamabad and also now living in Islamabad.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "id": "ArxXHoCsXvN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "vectors=[]\n",
        "i = 1\n",
        "ids = \"ID No:\"\n",
        "for doc in tqdm(docs):\n",
        "    vector = embeddings.embed_query(doc.page_content)\n",
        "    doc_id = str(f\"{ids}{i}\")\n",
        "    index.upsert(vectors=[(doc_id, vector, {'text': doc.page_content})])\n",
        "    i=i+1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYxHTMZEYCEv",
        "outputId": "ebe9c0da-f100-4fea-94b4-666e1c742361"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:01<00:00,  2.48it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Pinecone\n",
        "\n",
        "\n",
        "retriever=  Pinecone(index=index, embedding=embeddings, text_key=\"text\")\n",
        "\n",
        "\n",
        "# Convert it into a retriever compatible with RetrievalQA\n",
        "retriever = vector_store.as_retriever()"
      ],
      "metadata": {
        "id": "-wSLBJefgzh8"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"refine\",  # Other options: \"map_reduce\", \"refine\"\n",
        "    retriever=retriever\n",
        ")"
      ],
      "metadata": {
        "id": "RcEQRujyhNik"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"usman complete study from where?\"\n",
        "response = qa_chain.run(query)\n",
        "print(response)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwRQvyiqhoGw",
        "outputId": "b837ebf2-7cc8-45ca-99c5-2973e4e5068e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The provided context doesn't contradict the original answer.  Therefore, the original answer remains: Usman completed his studies at the University of Sargodha.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}